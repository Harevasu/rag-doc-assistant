# ===========================================
# RAG Document Assistant - Docker Environment
# ===========================================
# Copy this file to .env and configure your settings

# LLM Provider: "ollama" | "gemini" | "finetuned"
LLM_PROVIDER=gemini

# ===========================================
# Gemini API Configuration
# ===========================================
GOOGLE_API_KEY=your_google_api_key_here
EMBEDDING_MODEL=models/text-embedding-004
LLM_MODEL=gemini-2.0-flash

# ===========================================
# Ollama Configuration (Local LLM)
# ===========================================
# For Docker on Windows/Mac, use host.docker.internal
# For Docker on Linux, use your host IP or 172.17.0.1
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_LLM_MODEL=phi3:mini
OLLAMA_EMBED_MODEL=nomic-embed-text

# ===========================================
# Document Processing
# ===========================================
CHUNK_SIZE=512
CHUNK_OVERLAP=50

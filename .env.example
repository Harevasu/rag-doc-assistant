# LLM Provider: "finetuned" (trained model) | "ollama" (local) | "gemini" (API)
LLM_PROVIDER=finetuned

# Ollama Configuration (for local LLM - requires Ollama installed)
OLLAMA_HOST=http://localhost:11434
OLLAMA_LLM_MODEL=llama3.2
OLLAMA_EMBED_MODEL=nomic-embed-text

# Gemini Configuration (optional, for API-based LLM)
GOOGLE_API_KEY=your_api_key_here
GOOGLE_API_KEYS=key1,key2,key3,key4
EMBEDDING_MODEL=models/text-embedding-004
LLM_MODEL=gemini-2.0-flash

# Chunking Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
